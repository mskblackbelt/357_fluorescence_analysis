{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: The Kinetics of a Diffusion-Controlled Reaction\n",
        "authors:\n",
        "  - name: Author Name\n",
        "    email: example@cuny.edu\n",
        "    affiliations:\n",
        "      - ror: 00g2xk477\n",
        "      - institution: CUNY – Hunter College\n",
        "      - department: Chemistry\n",
        "date: 2024-01-01\n",
        "numbering:\n",
        "  heading_2: true\n",
        "  heading_3: true\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Change the contents of the above block to reflect your name, email, and the current date. Additionally, be sure to change the file name to match the following format:  \n",
        "*author's initials_title_date.ipynb*  \n",
        "For example:  \n",
        "*EF_Data Exploration_20210201.ipynb*  \n",
        "\n",
        "When you've done that, go ahead and delete this block. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Purpose"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["Describe the purpose of this document. "]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Library import\n",
        "We import all the required Python libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-06-16T14:44:50.874881Z",
          "start_time": "2019-06-16T14:44:38.616867Z"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# File handling\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "# Data manipulation\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "\n",
        "# Visualizations\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn-v0_8-notebook')\n",
        "mpl.rcParams['axes.spines.right'] = False\n",
        "mpl.rcParams['axes.spines.top'] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data import\n",
        "We retrieve all the required data for the analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prior to beginning this portion, make sure all of your data files have been uploaded to the same folder as this document (_i.e.,_ `~/357_fluorescence_analysis/`). \n",
        "If your data are still stored in a ZIP file, uncomment the bottom three lines in the cell below and fill in the relevant variables (`filename`, `data_folder`), then run the cell. If you already unzipped your files and have a folder full of fluorescence files, you'll need to set the variable `data_folder`, as later cells will use that value. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Unzip your fluorescence data into a subfolder\n",
        "\n",
        "# filename = Path('name of your zip file' + '.zip') # fill in the name of the file without the ZIP extension\n",
        "# data_folder = Path('name of destination folder') # fill in a name for a subfolder in which to place the text files\n",
        "# shutil.unpack_archive(filename, data_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a list of all of the files in your new folder. \n",
        "# If your files end in something other than \".TXT\", make that change here\n",
        "data_files = list(data_folder.glob(\"*.TXT\"))\n",
        "\n",
        "# List filenames so we can figure out our column naming in the next step. \n",
        "for file in data_files:\n",
        "    print(file) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This is an example of a simple function with a \"docstring\". \n",
        "# When writing code, docstrings provide a simple way to document\n",
        "# the purpose of a function within your code. When a user calls \n",
        "# `help(func)` on your function, the docstring will pull up and \n",
        "# tell the user how to proceed. \n",
        "\n",
        "# Create a simple function to import our fluorescence data and return \n",
        "# 1D arrays of wavelengths (wls) and absorption data (abs)\n",
        "# Skip first 31 rows, as data doesn't start until line 32\n",
        "# Default file from fluorometer uses tabs ('\\t') for separators, also\n",
        "# the default for the NumPy importers.\n",
        "def fluor_import(fname):\n",
        "    '''\n",
        "    A simple function to import fluorescence data from the \n",
        "    Hitachi F-2700 spectrophotometer. \n",
        "    Returns a  pair of 1D arrays of wavelengths (wls) \n",
        "    and absorption data (abs)\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    fname: file, str, pathlib.Path\n",
        "        File or filename to read. \n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    wls: ndarray \n",
        "        Wavelength values\n",
        "    intst: ndarray \n",
        "        Fluorescence data\n",
        "    '''\n",
        "    \n",
        "    data = np.genfromtxt(fname, skip_header=31, names=True)\n",
        "    wls = data['nm']\n",
        "    intst = data['Data']\n",
        "    return wls, intst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we use the `re` (Regular Expressions) library to search for patterns in text. Specifically, we're going to look for the percentage numbers in our filenames. This assumes your filenames have a two- or three-digit number representing the AN percent in your samples. There's a line included below that you'll need to _remove_ if you recorded the CBr<sub>4</sub> values instead. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create an empty dictionary to hold the contents of our assorted files\n",
        "fluor_dict = {} \n",
        "\n",
        "for file in data_files:\n",
        "    # Import the data using our function from the previous cell\n",
        "    wls, intst = fluor_import(file)\n",
        "    # Rename the dictionary entry to the percentage from your filename using\n",
        "    # the `re` library (regular expressions)\n",
        "    _val = re.findall(r'\\d{1,3}', file.stem)[0]\n",
        "    # Cast the key name to an integer so we can use it later for sorting and calculations\n",
        "    _val = int(_val)\n",
        "    # The next line turns the fluorophore percent into a quencher percent. \n",
        "    # Uncomment it if you recorded the AN value.\n",
        "    # _val = 100-_val\n",
        "    # Finally, add the data to our dictionary using the percentage as the key\n",
        "    fluor_dict[int(_val)] = intst\n",
        "\n",
        "# Print out the names of our keys to make sure they match the sample percentages\n",
        "fluor_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the spectra. Though we replaced `wls` each loop, they should \n",
        "# have all been the same, so we can use the current value of that variable. \n",
        "# Make sure your spectra decrease in intensity from 0%–100% CBr4\n",
        "# For clarity and later use, we'll sort our concentrations from low to high\n",
        "concs = np.array(sorted(fluor_dict.keys()))\n",
        "\n",
        "for key in concs:\n",
        "    plt.plot(wls, fluor_dict[key], label=key)\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data processing\n",
        "This constitutes the core of the notebook. Feel free to further split this section into subsections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile a sorted list of maximum intensities from each of our spectra\n",
        "# We're using `np.sort()` instead of `sorted()` because it will be good\n",
        "# practice for later to have a NumPy array as our output. \n",
        "intensities = []\n",
        "for conc in concs:\n",
        "    intensities.append(fluor_dict[conc].max())\n",
        "    \n",
        "intensities = np.array(intensities)\n",
        "\n",
        "# The first line grabs the largest value from each spectrum, \n",
        "# then divides the largest value in that list by each maximum (calculating I_0/I)\n",
        "intensities = intensities.max()/intensities \n",
        "\n",
        "for entry in zip(concs, intensities):\n",
        "    print(entry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Again, we'll define a simple function to help us out. \n",
        "def p2f(x): \n",
        "    '''Convert percentage to floating point numbers'''\n",
        "    return float(x)/100\n",
        "\n",
        "init_conc =  # Fill in the concentration (in molarity) of the original CBr4 solution\n",
        "\n",
        "# The next line uses \"list comprehension\" to apply a function to each item in a list.\n",
        "# We convert each string to a fractional value with p2f, \n",
        "# then multiply each fraction by the original concentration\n",
        "concs = [(p2f(item) * init_conc) for item in concs]\n",
        "\n",
        "plt.plot(concs, intensities, '.')\n",
        "plt.xlabel('Concentration (M)')\n",
        "plt.ylabel('$I_0/I$') \n",
        "plt.title('[Q] vs. $I_0/I$') # recall wrapping the input in `$` turns it into LaTeX math\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["### Collision radius via SES equation"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Variable setup\n",
        "# You'll need to create variables for the assorted values you'll use in \n",
        "# your calculations (e.g., tau_0, D, etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## SES: \n",
        "#    k = (8 * R_gas * T) / (3 * \\eta)\n",
        "#    k =  4 * \\pi * N_A * radius * D / 1000\n",
        "k_ses = \n",
        "\n",
        "# Can format numbers with the `:#.#g` syntax. `g` is an auto-formatter for \n",
        "# numbers that automatically trims and converts to scientific form if necessary. \n",
        "print(f\"The reaction constant with the SES equation is {k_ses:g} 1/(M*s).\") \n",
        "\n",
        "# Now calculate the radius\n",
        "radius_ses = \n",
        "print(f\"The reaction radius is {radius_ses:g} dm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["### Collision radius via SES equation"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Variable setup\n",
        "# Fill in appropriate variables for the SES equation. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## SES: k = (8 * R * T) / (3 * \\eta)\n",
        "k_ses = \n",
        "print(f\"The reaction constant with the SES equation is {k_ses:g} 1/(M*s).\") \n",
        "\n",
        "radius_ses = \n",
        "print(f\"The reaction radius is {radius_ses:g} dm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now we need to plot a line based on the SES calculations\n",
        "\n",
        "# We start by making a range of concentration values. \n",
        "# `linspace` is an ideal function as it makes evenly spaced \n",
        "# points between the start and stop values (50, by default). \n",
        "conc_data = np.linspace(0.000, init_conc)\n",
        "ses_fit = tau_0 * k_ses * conc_data + 1\n",
        "\n",
        "plt.plot(conc_data,ses_fit,'-',\n",
        "        concs[:7], intensities[:7], \".\")\n",
        "plt.xlabel('Concentration (M)')\n",
        "plt.ylabel('$I_0/I$')\n",
        "plt.title('$I_0/I$ vs. [Q]')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Collision radius via Stern-Vollmer relation (no transient term)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We're supposed to look at a linear fit for just the first few points. The `linregress()` function from `scipy.stats` works well for this (see the Plot Intro exercise for an example). Go ahead and plot a linear fit using different numbers of points from `concs` and `intensities` to see how the fit changes. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import linregress\n",
        "\n",
        "# Change this number to increase or decrease the number of points fit and plotted\n",
        "pts = 4\n",
        "fit_x = concs[:pts]\n",
        "fit_y = intensities[:pts]\n",
        "\n",
        "## Insert fitting routine here, use fit_x and fit_y as your parameters\n",
        "sv_fit = linregress(\n",
        "\n",
        "plt.plot(fit_x, fit_y, 'o', label='original data')\n",
        "plt.plot(fit_x, (sv_fit.slope * fit_x + sv_fit.intercept), label='fitted line')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "user_expressions": [
          {
            "expression": "f'{np.sqrt(2):1.4f}'",
            "result": {
              "data": {
                "text/plain": "'1.4142'"
              },
              "metadata": {},
              "status": "ok"
            }
          }
        ]
      },
      "source": [
        "Using the <code>\\{eval\\}\\`py_variable\\`</code> syntax we learned before, format and print the equation from your line as well as the standard error and $R^2$ value for the regression in a Markdown cell. \n",
        "\n",
        "For example, I can print out that $\\sqrt{2}$ is {eval}`f'{np.sqrt(2):1.4f}'`. \n",
        "\n",
        "Feel free to replace the text in this cell with your text and fit parameters. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "radius_fit = sv_fit.slope * 1000 / (4 * sp.constants.Avogadro  * np.pi * diffusion_hexane )\n",
        "print(f\"The reaction radius is {radius_fit:g} dm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We'll compare the fit from the previous method to one using the curve_fit \n",
        "# routine from scipy.optimize. In your summary, comment on the differences \n",
        "# (and why they exist). The key is in the y-intercept…\n",
        "\n",
        "def sv_func(conc, k_q):\n",
        "    return k_q * tau_0 * conc + 1\n",
        "\n",
        "\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "# Need to provide initial guess for parameter…\n",
        "sv_coeff, sv_cov = curve_fit(sv_func, concs[:4], intensities[:4], p0=2e10)\n",
        "\n",
        "sv_err = np.sqrt(np.diag(sv_cov))\n",
        "\n",
        "print(sv_coeff, \"\\n\", sv_err)\n",
        "radius_sv = sv_coeff[0] * 1000 / (4 * sp.constants.Avogadro  * np.pi * diffusion_hexane )\n",
        "print(f\"The reaction radius is {radius_sv:g} dm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Collision radius via full Stern-Vollmer relation (with transient term)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, you'll be fitting the full Stern-Vollmer relation and extracting the collision radius from that fit. You'll need to define functions for $a$, $b$, and $Y$, all of which are functions of $R$ and $[\\text{CBr}_4]$. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def a_const(R, conc):\n",
        "    return # fill in the equation for the \"a\" constant\n",
        "\n",
        "def b_const(R, conc): \n",
        "    return # fill in the equation for the \"b\" constant\n",
        "\n",
        "def y_const(R, conc):\n",
        "    # fill in the equation for the \"Y\" constant\n",
        "    # you must input `a` and `b` as \n",
        "    # `a_const(R, conc)` and `b_const(R, cons)`\n",
        "    # You'll find it helpful to do this one in multiple steps\n",
        "    return "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# It's worth playing with values of R and conc to see how they affect Y\n",
        "# Experiment with them here. \n",
        "print(y_const(5e-8, 1.5e-2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def intensity(conc, R):\n",
        "    return # fill in the equation for the intensity (I_0/I) as a function\n",
        "           # of conc, R, and y_const(conc, R)\n",
        "\n",
        "# The function requires a guess for all fitted parameters. \n",
        "# We'll use the value previously calculated with the SES equation. \n",
        "# It needs to be converted from dm to cm.\n",
        "sv_coeff_2 , sv_cov_2 = curve_fit(intensity, \n",
        "                                  concs, \n",
        "                                  intensities, \n",
        "                                  p0=[0.1 * radius_ses] \n",
        "                                 )\n",
        "\n",
        "sv_err_2 = np.sqrt(np.diag(sv_cov_2))\n",
        "\n",
        "print(f\"R = {sv_coeff_2[0]:g} ± {sv_err_2[0]:.2e} cm\")\n",
        "\n",
        "# Create a plot that shows your fit compared to the experimental data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results\n",
        "Describe and comment the most important results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n",
        "We report here relevant references:\n",
        "1. author1, article1, journal1, year1, url1\n",
        "2. author2, article2, journal2, year2, url2"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (PChem Lab)",
      "language": "python",
      "name": "pchem2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
